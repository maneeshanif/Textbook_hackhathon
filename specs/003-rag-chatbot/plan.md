# Implementation Plan: RAG Chatbot for Physical AI Textbook

**Branch**: `003-rag-chatbot` | **Date**: 2025-12-06 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/003-rag-chatbot/spec.md`

**Note**: This plan was generated by the `/sp.plan` command following comprehensive research and design phases.

## Summary

Build a production-ready RAG (Retrieval-Augmented Generation) chatbot that provides semantic search over Physical AI textbook content with streaming responses. Students can ask questions about robotics concepts and receive AI-generated answers with citations to specific textbook chapters. Supports guest and authenticated users, multilingual content (English/Urdu), chat history with 90-day retention for anonymous sessions, and feedback collection for quality improvement.

**Primary Technical Approach**: FastAPI backend with async architecture, Qdrant Cloud vector database (768-dim Gemini embeddings), Google Gemini API (text-embedding-004 + gemini-2.0-flash-exp) for embeddings and chat completions with streaming, Neon Serverless Postgres for chat history, Better Auth for authentication, React widget embedded in Docusaurus site. Optimized for hackathon deployment (Railway/Render backend + GitHub Pages frontend) with 5-7 day implementation timeline.

## Technical Context

**Language/Version**: Python 3.11+ (backend), TypeScript 5.x (frontend)  
**Primary Dependencies**: 
- Backend: FastAPI 0.109+, asyncpg 0.29+, qdrant-client 1.7+, google-genai 1.33+, structlog 24.1+
- Frontend: React 18.x, Docusaurus 3.x, EventSource polyfill  
**Storage**: 
- Vector DB: Qdrant Cloud (1GB free tier, ~5.6 MB usage estimated)
- Relational DB: Neon Serverless Postgres (512MB free tier, ~27 MB usage estimated)
- Frontend: localStorage for anonymous sessions (pre-auth migration)  
**Testing**: pytest (backend unit/integration), Jest + React Testing Library (frontend), locust (load testing)  
**Target Platform**: 
- Backend: Docker container on Railway/Render (Linux server)
- Frontend: Static site on GitHub Pages (Docusaurus SSG)  
**Project Type**: Web application (separate backend API + frontend static site)  
**Performance Goals**: 
- < 2s response time for queries (SC-001)
- < 500ms first chunk latency for streaming (FR-002)
- Support 50+ concurrent users (SC-006)
- 75%+ positive feedback rate (SC-007)  
**Constraints**: 
- Free tier infrastructure (Neon 512MB, Qdrant 1GB, Railway 500 hrs/month)
- Gemini API costs < $5/month (500 queries/day, free tier: 1500 requests/day)
- 0.7 minimum similarity threshold for vector search (FR-004)
- 90-day retention for anonymous sessions (FR-019)  
**Scale/Scope**: 
- 800 textbook chunks (400 English + 400 Urdu)
- 28 functional requirements (7 API endpoints)
- 4 database tables + 2 Qdrant collections
- 8-phase implementation (5-7 days for hackathon)

## Constitution Check

*All gates PASSED - ready for implementation*

✅ **Gate 1: Context7-First Development**  
   Fetched authoritative documentation for FastAPI, Qdrant, Google Gemini API, Better Auth via Context7.  
   Supplemented with Microsoft Learn code samples for asyncpg and structured logging.  
   All implementation patterns in research.md are from official latest docs.

✅ **Gate 2: Test-Driven Development**  
   Testing strategy defined in quickstart.md Phases 1-7.  
   Unit tests for endpoint logic, integration tests for E2E flows, load tests for 50+ concurrent users.

✅ **Gate 3: Subagent Delegation**  
   Mapped to `rag-service` subagent (backend RAG operations).  
   Mapped to `book-builder` subagent (Docusaurus frontend integration).  
   Mapped to `auth-personalization` subagent (Better Auth + user preferences).

✅ **Gate 4: Simplicity First**  
   Chose in-memory metrics collector over Prometheus/Grafana (simpler for hackathon).  
   Using Better Auth REST API directly instead of Python SDK (doesn't exist, REST is simpler).  
   Direct MDX parsing with unified/remark (no unnecessary abstraction layers).

✅ **Gate 5: No Premature Optimization**  
   Using asyncpg connection pooling (proven 3-5x faster than psycopg3 per benchmarks).  
   HNSW index in Qdrant (default, battle-tested for approximate nearest neighbor).  
   No custom caching layer (rely on database query caching and Qdrant's built-in optimizations).

✅ **Gate 6: Clear Error Handling**  
   Defined error taxonomy in contracts/README.md (400/401/404/429/500/503).  
   Structured logging with request_id for traceability (Phase 7).  
   Health check endpoint monitors all dependencies (Postgres, Qdrant, Gemini API).

✅ **Gate 7: Avoid Redundant Tools**  
   Single vector DB (Qdrant) for semantic search.  
   Single relational DB (Neon Postgres) for structured data.  
   No separate message queue (streaming responses via SSE sufficient).

✅ **Gate 8: Document Decisions**  
   4 ADRs documented: framework stack, i18n architecture, content organization, custom components.  
   All clarification decisions captured in spec.md with rationale and impact.

✅ **Gate 9: Small, Testable Changes**  
   8-phase implementation in quickstart.md, each phase has clear acceptance criteria.  
   Each phase delivers a testable increment (health check → ingestion → core RAG → history → etc.).

✅ **Gate 10: Security Best Practices**  
   Parameterized SQL queries prevent injection (asyncpg $1, $2 syntax).  
   Session tokens hashed with SHA-256 before storage.  
   API key authentication for admin endpoints.  
   TLS encryption for all connections (Postgres SSL, Qdrant HTTPS, Gemini API HTTPS).

✅ **Gate 11: Cost Consciousness**  
   Gemini API: FREE tier with 1500 requests/day (text-embedding-004 + gemini-2.0-flash-exp).  
   Free tier infrastructure: Neon 512MB (27MB used), Qdrant 1GB (3.5MB used with 768-dim), Railway 500 hrs/month.  
   Total monthly cost estimate: $0 (100% free tier).

✅ **Gate 12: Deployment Readiness**  
   Dockerfile for backend (FastAPI + gunicorn + async workers).  
   Railway/Render deployment scripts in quickstart.md.  
   GitHub Pages deployment for static frontend (Docusaurus build).  
   Environment variable checklist for production (12 required env vars documented).

## Project Structure

### Documentation (this feature)

```text
specs/003-rag-chatbot/
├── spec.md              # Feature requirements (28 FRs, 9 SCs, 4 clarifications)
├── plan.md              # This file - comprehensive implementation plan
├── research.md          # Phase 0 - technology research (24KB, 8 topics, 20+ code samples)
├── data-model.md        # Phase 1 - database schemas (Postgres + Qdrant)
├── quickstart.md        # Phase 1 - 8-phase implementation guide (5-7 days)
└── contracts/           # Phase 1 - API specifications
    ├── README.md        # Contracts summary, validation rules, testing checklist
    └── openapi-spec.yaml # OpenAPI 3.1 spec (7 endpoints, full request/response schemas)
```

### Source Code (repository root)

```text
# Backend (Python FastAPI)
rag-chatbot-backend/
├── app/
│   ├── __init__.py
│   ├── main.py                 # FastAPI app entry point
│   ├── config.py               # Settings from env vars (pydantic-settings)
│   ├── database.py             # asyncpg connection pool
│   ├── qdrant_client.py        # Qdrant async client wrapper
│   ├── api/
│   │   ├── __init__.py
│   │   ├── chat.py             # Chat endpoints (query, history, migrate, feedback)
│   │   ├── admin.py            # Admin endpoints (ingest, metrics)
│   │   └── health.py           # Health check endpoint
│   ├── middleware/
│   │   ├── auth.py             # Better Auth session validation
│   │   └── logging.py          # Request tracing middleware (structlog)
│   ├── services/
│   │   ├── rag.py              # RAG service (vector search + LLM streaming)
│   │   ├── ingestion.py        # MDX parsing + embedding pipeline
│   │   └── metrics.py          # In-memory metrics collector
│   └── models/
│       ├── schemas.py          # Pydantic request/response models
│       └── database.py         # Database model classes (if using ORM, optional)
├── scripts/
│   ├── ingest_textbook.py      # CLI for content ingestion
│   └── cleanup_sessions.py     # Cron job for 90-day retention
├── migrations/
│   └── 001_init_schema.sql     # Postgres schema initialization
├── tests/
│   ├── unit/
│   │   ├── test_rag.py         # RAG service unit tests
│   │   ├── test_ingestion.py   # Ingestion pipeline tests
│   │   └── test_metrics.py     # Metrics collector tests
│   ├── integration/
│   │   ├── test_chat_api.py    # E2E chat flow tests
│   │   ├── test_auth_flow.py   # Authentication integration tests
│   │   └── test_history_api.py # History retrieval tests
│   └── load/
│       └── locustfile.py       # Load testing (50+ concurrent users)
├── Dockerfile                  # Docker image for deployment
├── requirements.txt            # Python dependencies
├── .env.example                # Environment variable template
└── README.md                   # Backend setup instructions

# Frontend (React + Docusaurus)
book/                           # Existing Docusaurus site
├── src/
│   └── components/
│       └── ChatWidget/
│           ├── index.tsx       # Main chat widget component
│           ├── SelectionHandler.tsx # Text selection UI
│           ├── MessageList.tsx # Message rendering with citations
│           └── styles.module.css # Widget styles (responsive, RTL-aware)
├── tests/
│   └── unit/
│       ├── ChatWidget.test.tsx # Widget component tests
│       └── SelectionHandler.test.tsx # Selection logic tests
└── [existing Docusaurus structure preserved]
```

**Structure Decision**: Web application with separate backend and frontend
- **Backend**: Standalone FastAPI service (stateless, horizontally scalable)
- **Frontend**: Embedded React widget in existing Docusaurus site (no separate app)
- **Communication**: REST API + Server-Sent Events (SSE) for streaming
- **Deployment**: Backend on Railway/Render (Docker), Frontend on GitHub Pages (static)

**Rationale**:
- Separation of concerns (API can be reused for mobile apps, CLI tools)
- Independent scaling (backend scales with traffic, frontend is CDN-served)
- Technology fit (Docusaurus best for docs, FastAPI best for async Python APIs)
- Hackathon-friendly (parallel development: backend team + frontend team)

## Complexity Tracking

> No constitution violations detected. All complexity is justified by functional requirements.

**Complexity Review**:
- ✅ Single backend language (Python) - justified for FastAPI async ecosystem
- ✅ Single frontend language (TypeScript) - justified for React + Docusaurus integration
- ✅ Two databases (Postgres + Qdrant) - justified for different data models (relational vs vector)
- ✅ External auth service (Better Auth) - justified for OAuth support without reinventing auth
- ✅ Streaming architecture (SSE) - justified for real-time user experience requirement (FR-002)

**No simpler alternatives available that meet all 28 functional requirements.**

---

## Research Summary

**Comprehensive research completed in Phase 0** (see [research.md](./research.md) for full details with code samples)

### 1. FastAPI + Qdrant Integration
- Async patterns with `AsyncQdrantClient` and `asyncpg`
- Streaming responses using `StreamingResponse` and async generators
- Error handling with `HTTPException` and custom middleware
- Vector search with filters (`Filter`, `FieldCondition`, `MatchValue`)

### 2. Google Gemini Embeddings + Chat Completions
- `text-embedding-004` model (768 dimensions default, configurable 1-768)
- `gemini-2.0-flash-exp` streaming with async patterns
- Batch embedding generation for ingestion pipeline
- Free tier: 1500 requests/day (generous for hackathon)

### 3. Better Auth Integration
- REST API approach (no Python SDK available)
- Session validation via `GET /api/auth/session` with cookie headers
- JWT token format: `better-auth.session_token` cookie
- Guest/authenticated routing in FastAPI middleware

### 4. Neon Serverless Postgres
- asyncpg 3-5x faster than psycopg3 for async workloads
- Connection pooling: `min_size=2, max_size=10` for free tier
- Serverless driver handles connection lifecycle automatically
- 90-day cleanup job using `DELETE ... WHERE created_at < NOW() - INTERVAL '90 days'`

### 5. React Chat Widget in Docusaurus
- Swizzling `Footer` component to embed chat widget globally
- localStorage for anonymous session persistence (pre-auth)
- `EventSourcePolyfill` for cross-browser SSE support
- Text selection API (`window.getSelection()`) for context queries

### 6. MDX Content Ingestion
- `unified` + `remark-parse` for MDX parsing (AST-based)
- Exclude code blocks from embedding (filter `code` nodes)
- Chunking strategy: 500 tokens/chunk, 50-token overlap
- Deterministic chunk IDs: `{module}_{week}_{section}_chunk_{index}`

### 7. Structured Logging
- `structlog` with JSON formatter for machine-readable logs
- Request tracing middleware: unique `request_id` per request
- Log context: `request_id`, `method`, `path`, `status_code`, `duration_ms`
- Query logging: user query, language, similarity scores, below-threshold flag

### 8. Vector Search Quality Metrics
- In-memory collector: latency percentiles (p50, p95, p99)
- Similarity score tracking: average, distribution, below-threshold count
- Feedback metrics: positive rate calculation (target: 75%+)
- Admin metrics endpoint: `/api/admin/metrics` with aggregated stats

---

## Data Model

**Comprehensive schemas defined in Phase 1** (see [data-model.md](./data-model.md) for full details)

### Postgres Tables
1. **users** - Authenticated user accounts (UUID, email, name, created_at)
2. **chat_sessions** - Conversation threads (UUID, user_id nullable, session_token, language, last_activity)
3. **chat_messages** - Individual messages (UUID, session_id, role, content, metadata JSONB, created_at)
4. **feedback_ratings** - Thumbs up/down feedback (UUID, message_id, rating ±1, feedback_text, created_at)

**Key Relationships**:
- One user → many sessions (1:N)
- One session → many messages (1:N)
- One message → many feedback ratings (1:N, typically 1 rating per user)

**Indexes**:
- `idx_chat_sessions_user` - Fast user session lookup
- `idx_chat_sessions_token` - Anonymous session lookup by token (partial index)
- `idx_chat_messages_session` - Efficient history retrieval (covering index on session_id, created_at)
- `idx_feedback_ratings_message` - Feedback lookup per message

### Qdrant Collections
1. **textbook_chunks_en** - English content vectors (400 chunks)
2. **textbook_chunks_ur** - Urdu content vectors (400 chunks)

**Vector Configuration**:
- Dimensions: 768 (Gemini text-embedding-004 default)
- Distance metric: Cosine similarity
- HNSW index: `ef_construct=100, m=16` (default, optimal for most use cases)

**Payload Schema**:
```json
{
  "text": "chunk content",
  "chapter": "1.1.2",
  "section": "Introduction to Kinematics",
  "module": "module-1",
  "week": "week-1-2",
  "language": "en",
  "file_path": "docs/module-1/week-1-2/index.mdx",
  "chunk_index": 0,
  "token_count": 487
}
```

**Storage Estimates**:
- Postgres: ~27 MB (18x headroom on 512MB free tier)
- Qdrant: ~5.6 MB (177x headroom on 1GB free tier)

---

## API Contracts

**7 endpoints fully specified in Phase 1** (see [contracts/](./contracts/) for full OpenAPI 3.1 spec)

### Chat Endpoints
1. **POST /api/chat/query** - Submit query, get streaming RAG response with citations
2. **POST /api/chat/query-selection** - Query with user-selected text context
3. **GET /api/chat/history** - Retrieve paginated session history (limit/offset)
4. **POST /api/chat/migrate** - Migrate anonymous session to authenticated user
5. **POST /api/chat/feedback** - Submit thumbs up/down feedback on assistant response

### Admin Endpoints
6. **POST /api/admin/ingest** - Trigger content re-embedding (requires API key)
7. **GET /api/health** - Health check for dependencies (Postgres, Qdrant, Gemini API)

**Request/Response Patterns**:
- Standard JSON for non-streaming endpoints
- Server-Sent Events (SSE) for streaming chat responses
- Error responses include `error`, `message`, `details` fields
- All responses include `X-Request-ID` header for tracing

**Authentication**:
- Anonymous users: `session_token` in request body or query param
- Authenticated users: `better-auth.session_token` cookie
- Admin endpoints: `X-API-Key` header

**Rate Limiting**:
- Anonymous: 10 requests/minute per session_token
- Authenticated: 30 requests/minute per user_id
- Admin: 100 requests/minute per API key

---

## Implementation Sequence

**8-phase rollout over 5-7 days** (see [quickstart.md](./quickstart.md) for detailed tasks and acceptance criteria)

### Phase 1: Backend Foundation (Day 1, 2-3 hours)
- FastAPI project setup with health check endpoint
- Database connection pools (asyncpg for Postgres, AsyncQdrantClient for Qdrant)
- Environment variable configuration (.env with 12 required vars)
- Run initial Postgres migrations (4 tables)

**Acceptance**: `GET /api/health` returns 200 with all dependencies "ok"

### Phase 2: Content Ingestion Pipeline (Day 1-2, 3-4 hours)
- MDX parsing script with unified/remark (exclude code blocks)
- Chunking logic: 500 tokens/chunk, 50-token overlap, deterministic IDs
- Batch embedding generation with Gemini API
- Qdrant collection creation and upsert (idempotent)
- Admin ingestion endpoint with API key auth

**Acceptance**: 800 vectors upserted (400 English + 400 Urdu), all payloads validated

### Phase 3: Core RAG Endpoint (Day 2-3, 4-5 hours)
- Vector search with language filtering and 0.7 similarity threshold
- LLM streaming with Gemini `gemini-2.0-flash-exp` (async patterns)
- SSE response generation (chunks + citations + [DONE])
- Save messages to database (user + assistant roles)
- Query-selection endpoint variant (prepend selected text to context)

**Acceptance**: Streaming response delivers chunks < 100ms latency, citations included, below-threshold queries logged

### Phase 4: Chat History & Cleanup (Day 3, 2-3 hours)
- History endpoint with pagination (limit/offset)
- Session validation (anonymous vs authenticated)
- Cleanup script for 90-day retention (cron job)
- Cascade deletion for messages and feedback

**Acceptance**: History retrieval works for anonymous + authenticated, cleanup script deletes old sessions

### Phase 5: Authentication Integration (Day 3-4, 3-4 hours)
- Better Auth session validation middleware (REST API calls)
- User table management (insert/update on auth)
- Migration endpoint (localStorage → database)
- Authenticated session routing (exclude from cleanup)

**Acceptance**: Sign-in flow works, migration transfers messages, authenticated sessions persistent

### Phase 6: Frontend Chat Widget (Day 4-5, 4-6 hours)
- React component with SSE streaming support
- localStorage fallback for anonymous users
- Text selection handler with query prompt
- Citation rendering with clickable chapter links
- Language toggle (English/Urdu)
- Embed in Docusaurus footer (swizzling)

**Acceptance**: Widget renders, streaming updates in real-time, localStorage persists, text selection works

### Phase 7: Observability (Day 5, 2-3 hours)
- Structured logging with structlog (JSON formatter)
- Request tracing middleware (unique request_id)
- In-memory metrics collector (latency percentiles, similarity scores)
- Admin metrics endpoint (aggregated stats)
- X-Request-ID header in all responses

**Acceptance**: Logs in JSON format, metrics endpoint returns stats, request_id in error responses

### Phase 8: Bonus Features (Day 6-7, Optional)
- Urdu content validation and testing
- User preference storage (language, difficulty level)
- Cross-device sync (already works via authenticated sessions)
- Feedback UI (thumbs up/down buttons)
- Admin analytics dashboard (positive feedback rate)

**Acceptance**: Urdu queries work, preferences saved, feedback buttons functional, analytics >= 75% positive rate

---

## Deployment Strategy

### Development Environment
```bash
# Backend
cd rag-chatbot-backend
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env  # Fill in API keys
uvicorn app.main:app --reload

# Frontend
cd book
npm install
npm run start  # Docusaurus with hot reload
```

### Production Deployment

**Backend (Railway or Render)**:
1. Create Dockerfile (Python 3.11 + gunicorn + async workers)
2. Set environment variables (12 required: NEON_CONNECTION_STRING, QDRANT_URL, GEMINI_API_KEY, etc.)
3. Deploy via Railway CLI: `railway login && railway up`
4. Run migrations: `railway run python scripts/migrate.py`
5. Trigger ingestion: `curl -X POST -H "X-API-Key: ..." https://api.yourapp.com/api/admin/ingest`

**Frontend (GitHub Pages)**:
1. Configure base URL in `docusaurus.config.ts`: `baseUrl: '/your-repo-name/'`
2. Build static site: `npm run build`
3. Deploy: `npm run deploy` (pushes to gh-pages branch)
4. Enable GitHub Pages in repo settings (source: gh-pages branch)

**Environment Variables (Production)**:
```env
# Database
NEON_CONNECTION_STRING=postgresql://user:pass@host/db

# Qdrant
QDRANT_URL=https://xxx.qdrant.io
QDRANT_API_KEY=your-api-key

# Gemini API
GEMINI_API_KEY=...

# Better Auth
BETTER_AUTH_URL=https://auth.yourapp.com

# Security
ADMIN_API_KEY=secure-random-key-here

# CORS
CORS_ORIGINS=https://yourdomain.com,https://www.yourdomain.com

# Logging
LOG_LEVEL=INFO
ENVIRONMENT=production
```

**Monitoring**:
- Health check: `GET /api/health` (uptime monitoring with UptimeRobot)
- Metrics: `GET /api/admin/metrics` (daily review of latency, similarity, feedback)
- Logs: Railway/Render dashboard (structured JSON logs with request_id)
- Costs: Gemini API Console (track request usage within free tier: 1500/day)

---

## Risk Mitigation

### Technical Risks
1. **Gemini API Rate Limits**
   - **Mitigation**: Free tier allows 1500 requests/day, implement request queueing if needed
   - **Fallback**: Cache common queries (10 most frequent → precomputed responses)

2. **Vector Search Quality (Below 0.7 Threshold)**
   - **Mitigation**: Log all below-threshold queries (FR-021), manual review weekly
   - **Fallback**: Return "no relevant content" message with suggestion to rephrase

3. **Free Tier Exhaustion**
   - **Postgres**: 27 MB used / 512 MB limit (18x headroom)
   - **Qdrant**: 5.6 MB used / 1GB limit (177x headroom)
   - **Railway**: Monitor usage dashboard, upgrade if > 400 hrs/month
   - **Mitigation**: Implement usage alerts at 80% capacity

### Operational Risks
1. **Concurrent User Spike (> 50)**
   - **Mitigation**: Load test with locust (50+ concurrent users target)
   - **Fallback**: Horizontal scaling on Railway (add more instances)

2. **90-Day Cleanup Failure**
   - **Mitigation**: Cron job with logging, manual verification weekly
   - **Fallback**: On-demand cleanup script if automated job fails

3. **Better Auth Service Downtime**
   - **Mitigation**: Graceful degradation (guest mode still works)
   - **Fallback**: Show "authentication temporarily unavailable" banner

---

## Success Metrics

### Functional Requirements (28 FRs) - All Must Pass
- [ ] FR-001 to FR-008: Core RAG functionality (vector search, streaming, citations)
- [ ] FR-009 to FR-011: Guest access and migration
- [ ] FR-012 to FR-015: Content ingestion and quality
- [ ] FR-016 to FR-019: Chat history and retention
- [ ] FR-020 to FR-022: Authentication and security
- [ ] FR-023: Multilingual support (English/Urdu)
- [ ] FR-024 to FR-026: Observability (logging, metrics, health check)
- [ ] FR-027 to FR-028: Bonus features (personalization, cross-device sync)

### Success Criteria (9 SCs) - All Must Pass
- [ ] SC-001: < 2s response time (measure with `time curl ...`)
- [ ] SC-002: Accurate citations (manual review of 20 sample queries)
- [ ] SC-003: Smooth streaming (visual inspection, < 100ms chunk latency)
- [ ] SC-004: Reliable ingestion (800 vectors, no errors)
- [ ] SC-005: Secure authentication (manual OAuth flow test)
- [ ] SC-006: 50+ concurrent users (locust load test, 0% error rate)
- [ ] SC-007: 75%+ positive feedback rate (check `/api/admin/analytics`)
- [ ] SC-008: Deployment within 7 days (calendar tracking)
- [ ] SC-009: Free tier compliance (monitor dashboards daily)

### Analytics Dashboard (Post-Launch)
- Daily active users (7-day rolling average)
- Average queries per user
- Positive feedback rate (target: 75%+)
- Below-threshold query rate (investigate if > 10%)
- Response time percentiles (p50, p95, p99)
- Gemini API request usage and free tier remaining

---

## Next Steps

**Immediate**: Run `/sp.tasks` command to break down plan into granular, testable tasks
- Input: This plan.md + spec.md
- Output: tasks.md with subtasks for each phase
- Format: Checklist with acceptance tests embedded

**Post-Tasks**: Begin Phase 1 implementation (Backend Foundation)
- Set up FastAPI project structure
- Configure database connections
- Implement health check endpoint
- Run first round of tests

**Continuous**: Update Prompt History Records (PHRs) after each phase completion
- Document decisions made during implementation
- Track deviations from plan (with justification)
- Capture lessons learned for future features

---

**Plan Status**: ✅ COMPLETE  
**Dependencies**: Phase 0 research complete, Phase 1 design artifacts generated  
**Blockers**: None - ready for task breakdown  
**Estimated Delivery**: 5-7 days (hackathon timeline)
