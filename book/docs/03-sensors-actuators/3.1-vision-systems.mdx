---
id: vision-systems
title: 3.1 Vision Systems
sidebar_position: 1
---

# 3.1 Vision Systems

## Introduction

Vision is the most information-rich sense for humanoid robots. Modern vision systems provide:
- RGB images for object recognition
- Depth information for 3D reconstruction
- High frame rates for real-time control

## RGB Cameras

### Specifications
- **Resolution**: 1920×1080 (Full HD) to 4K
- **Frame Rate**: 30-120 fps
- **Field of View (FOV)**: 60-120 degrees
- **Interface**: USB, MIPI CSI, Ethernet

### Applications
- Object detection and tracking
- Face recognition
- Visual servoing (image-based control)

### Example: Object Detection

```python
import cv2
from ultralytics import YOLO

# Load YOLOv8 model
model = YOLO('yolov8n.pt')

# Open camera
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # Detect objects
    results = model(frame)
    annotated = results[0].plot()
    
    cv2.imshow('Object Detection', annotated)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

## Depth Sensors

### Stereo Cameras
**Principle**: Triangulation using two cameras with known baseline.

$$
Z = \frac{f \cdot B}{d}
$$

Where:
- $Z$: Depth
- $f$: Focal length
- $B$: Baseline (distance between cameras)
- $d$: Disparity (pixel difference between left and right images)

**Examples**: ZED 2, OAK-D, Intel RealSense D435

### Time-of-Flight (ToF) Cameras
**Principle**: Measure time for light pulse to return.

**Advantages**:
- Fast depth acquisition
- Works in low light

**Limitations**:
- Limited range (typically &lt;5 meters)
- Affected by reflective surfaces

**Examples**: Microsoft Kinect Azure, Intel RealSense L515

## Lidar

### Principle
**LiDAR** (Light Detection and Ranging) uses laser pulses to measure distances.

**Types**:
1. **2D Lidar**: Single scanning plane (used in mobile robots)
2. **3D Lidar**: Multiple scanning planes or rotating scanner

### Specifications
- **Range**: 10-100+ meters
- **Accuracy**: ±2 cm
- **Angular Resolution**: 0.1-1 degree
- **Scan Rate**: 10-20 Hz

### Applications
- SLAM (Simultaneous Localization and Mapping)
- Obstacle avoidance
- Navigation in outdoor environments

### Example: Point Cloud Visualization

```python
import open3d as o3d

# Load point cloud
pcd = o3d.io.read_point_cloud("scene.pcd")

# Visualize
o3d.visualization.draw_geometries([pcd])
```

## Sensor Fusion

Combining multiple sensors improves robustness:

**RGB + Depth**:
- 3D object detection
- Scene understanding

**Camera + Lidar**:
- Accurate depth + high-resolution texture
- Used in autonomous vehicles

**Camera + IMU**:
- Visual-inertial odometry (VIO)
- Robust to camera occlusions

## Key Takeaways

- **RGB Cameras**: High-resolution images, object recognition
- **Depth Sensors**: Stereo cameras (triangulation), ToF (time measurement)
- **Lidar**: Long-range, accurate 3D mapping
- **Sensor Fusion**: Combining modalities improves perception

---

**Next:** [3.2 Force and IMU Sensors](./3.2-force-imu-sensors)
