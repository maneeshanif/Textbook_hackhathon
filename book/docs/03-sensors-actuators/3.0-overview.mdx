---
id: overview
title: 3.0 Chapter Overview
sidebar_position: 0
---

# Chapter 3: Sensors and Actuators

## Learning Objectives

By the end of this chapter, you will be able to:

- Understand different sensor types (vision, force, IMU, proprioceptive)
- Select appropriate sensors for humanoid robot applications
- Explain actuator technologies (electric motors, hydraulics, SEA)
- Analyze trade-offs in actuator selection
- Integrate sensor data for robot perception and control

## Chapter Overview

Sensors and actuators are the **interface between computation and the physical world**. Without sensors, robots are blind. Without actuators, they cannot move. This chapter covers:

- **Vision Systems**: RGB cameras, depth sensors, lidar for environment perception
- **Force/Torque Sensors**: Measuring contact forces for manipulation and balance
- **Inertial Sensors**: IMUs for orientation and acceleration
- **Actuator Technologies**: Electric motors, hydraulics, pneumatics, series elastic actuators

## Prerequisites

- Basic physics (force, torque, voltage, current)
- Understanding of coordinate frames (from Chapter 2)
- Signal processing fundamentals (optional but helpful)

## Chapter Structure

1. **3.1 Vision Systems** — Cameras, depth sensors, lidar
2. **3.2 Force and IMU Sensors** — Force/torque sensors, accelerometers, gyroscopes
3. **3.3 Actuator Technologies** — Motors, hydraulics, SEAs
4. **3.4 Exercises** — Sensor calibration, motor selection
5. **3.5 Summary** — Key takeaways and further reading

## Estimated Time

- Reading: 60 minutes
- Exercises: 90 minutes
- Total: ~2.5 hours

---

**Ready to begin?** Continue to [3.1 Vision Systems](./3.1-vision-systems)
