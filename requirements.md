

# **Hackathon I: Create a Textbook for Teaching Physical AI & Humanoid Robotics Course**

The future of work will be a partnership between people, intelligent agents (AI software), and robots. This shift won't necessarily eliminate jobs but will change what humans do, leading to a massive demand for new skills. We have already written a book on AI agents. Therefore, we want you to write a textbook to teach a course in **Physical AI & Humanoid Robotics** (The course details are documented below).

---

## **Excel in the Hackathon and Launch Your Journey as an AI Startup Founder üöÄ**

We‚Äôve recently launched **Panaversity (panaversity.org)**, an initiative focused on teaching cutting-edge AI courses. Alongside this, we‚Äôre working on publishing our first book, which you can explore at **ai-native.panaversity.org**.

Our next milestone is to build a portal where authors can create AI-native technical textbooks, and readers can easily access and learn from them using AI Agents. We also plan to publish O/A Level, Science, Engineering, and Medical AI-native books to support students and professionals across disciplines.

If you perform well in this hackathon, you may be invited for an interview to join the Panaversity core team and potentially step into the role of a startup founder within this growing ecosystem.

You will get a chance to work with Panaversity founders **Zia, Rehan, Junaid, and Wania** and become the very best. You may also get a chance to teach at **Panaversity, PIAIC, and GIAIC**.

---

# **Requirements**

You are required to complete a unified book project using **Claude Code** and **Spec-Kit Plus**.
The core deliverables are:

---

### **1. AI/Spec-Driven Book Creation**

Write a book using **Docusaurus** and deploy it to GitHub Pages.
You will use:

* Spec-Kit Plus: [https://github.com/panaversity/spec-kit-plus/](https://github.com/panaversity/spec-kit-plus/)
* Claude Code: [https://www.claude.com/product/claude-code](https://www.claude.com/product/claude-code)

---

### **2. Integrated RAG Chatbot Development**

Build and embed a **Retrieval-Augmented Generation (RAG)** chatbot within the published book.

The chatbot must use:

* OpenAI Agents / ChatKit SDKs
* FastAPI
* Neon Serverless Postgres
* Qdrant Cloud Free Tier

The chatbot must answer questions about the book **and** questions based only on text selected by the user.

---

### **3. Scoring**

* **Base Score:** 100 points
* **Bonus 1:** +50 points ‚Üí reusable intelligence via Claude Code Subagents and Agent Skills
* **Bonus 2:** +50 points ‚Üí implement Signup/Signin using [https://www.better-auth.com/](https://www.better-auth.com/)
* **Bonus 3:** +50 points ‚Üí personalized chapter content for logged user
* **Bonus 4:** +50 points ‚Üí Urdu translation feature per chapter

---

# **Timeline**

* **Submission Deadline:** Sunday, **Nov 30, 2025** at 06:00 PM
* **Live Presentations:** Sunday, **Nov 30, 2025** at 6:00 PM on Zoom

Top submissions will be invited via WhatsApp to present live.

> *Note:* All submissions are evaluated. Live presentation is by invitation only.

---

# **Submit and Present Your Project**

Submit your project here:
**[https://forms.gle/CQsSEGM3GeCrL43c8](https://forms.gle/CQsSEGM3GeCrL43c8)**

### **Submit the following:**

* Public GitHub Repo Link
* Published Book Link (GitHub Pages or Vercel)
* Demo video (under 90 seconds)
* WhatsApp number

### **Zoom Link (Nov 30, 2025 at 6 PM)**

Join Zoom Meeting:
[https://us06web.zoom.us/j/84976847088?pwd=Z7t7NaeXwVmmR5fysCv7NiMbfbhIda.1](https://us06web.zoom.us/j/84976847088?pwd=Z7t7NaeXwVmmR5fysCv7NiMbfbhIda.1)

* **Meeting ID:** 849 7684 7088
* **Passcode:** 305850

---

# **The Course Details ‚Äî Physical AI & Humanoid Robotics**

## **Focus:** AI Systems in the Physical World (Embodied Intelligence)

## **Goal:** Bridge the gap between digital brain and physical body.

Students apply AI knowledge to control humanoid robots in simulation and real hardware.

---

# **Quarter Overview**

The future of AI extends beyond digital spaces into the physical world.
This capstone quarter introduces **Physical AI**‚ÄîAI systems that function in reality and comprehend physical laws.

Students learn to:

* Design
* Simulate
* Deploy humanoid robots
* Build natural human-robot interactions

Technologies used:

* **ROS 2**
* **Gazebo**
* **Unity**
* **NVIDIA Isaac**

---

# **Module 1: The Robotic Nervous System (ROS 2)**

**Focus:** Middleware for robot control.

* ROS 2 Nodes, Topics, Services
* Connect Python Agents ‚Üí ROS via `rclpy`
* Understanding URDF for humanoids

---

# **Module 2: The Digital Twin (Gazebo & Unity)**

**Focus:** Physics simulation & environment building.

* Simulating gravity, physics, collisions
* Unity high-fidelity visualization
* Simulated sensors (LiDAR, depth cameras, IMUs)

---

# **Module 3: The AI-Robot Brain (NVIDIA Isaac‚Ñ¢)**

**Focus:** Advanced perception & simulation.

* Isaac Sim for realistic rendering
* Isaac ROS for VSLAM & navigation
* Nav2 for bipedal movement planning

---

# **Module 4: Vision-Language-Action (VLA)**

**Focus:** LLMs + Robotics

* Voice-to-Action using Whisper
* LLM-based cognitive planning ("Clean the room")
* Translate language ‚Üí ROS 2 action pipeline

---

# **Capstone Project: The Autonomous Humanoid**

Robot performs:

1. Accepts voice command
2. Plans the task
3. Navigates obstacles
4. Identifies an object
5. Manipulates it

---

# **Why Physical AI Matters**

Humanoid robots excel because they:

* Match human physical form
* Function in human environments
* Use abundant real-world interaction data

This is a shift from purely digital AI ‚Üí **Embodied Intelligence**.

---

# **Learning Outcomes**

* Understand embodied AI
* Master ROS 2
* Simulate in Gazebo & Unity
* Use NVIDIA Isaac platform
* Design humanoid robot interactions
* Integrate GPT models into robotics

---

# **Weekly Breakdown**

### **Weeks 1‚Äì2: Intro to Physical AI**

* Embodied intelligence
* Humanoid robotics overview
* Sensors (LIDAR, IMU, cameras)

### **Weeks 3‚Äì5: ROS 2 Fundamentals**

* Nodes, topics, services
* ROS 2 packages
* Launch files

### **Weeks 6‚Äì7: Robot Simulation**

* Gazebo setup
* URDF/SDF
* Physics + sensor simulation
* Unity basics

### **Weeks 8‚Äì10: NVIDIA Isaac**

* Isaac Sim
* Perception & manipulation
* Reinforcement learning
* Sim-to-Real

### **Weeks 11‚Äì12: Humanoid Robotics**

* Kinematics & dynamics
* Bipedal locomotion
* Grasping & manipulation
* Human-robot interaction

### **Week 13: Conversational Robotics**

* GPT models in robots
* Speech recognition
* Multi-modal interactions

---

# **Assessments**

* ROS 2 package
* Gazebo simulation
* Isaac perception pipeline
* Capstone humanoid robot project

---

# **Hardware Requirements**

Physical AI requires heavy computation:

* Physics Simulation
* Vision (SLAM, CV)
* Generative AI (LLMs/VLA)

Main categories:

---

## **1. The ‚ÄúDigital Twin‚Äù Workstation (Required)**

* **GPU:** NVIDIA RTX 4070 Ti (min), ideal 3090/4090
* **CPU:** Intel i7 13th Gen+ or Ryzen 9
* **RAM:** 64 GB DDR5
* **OS:** Ubuntu 22.04

---

## **2. The ‚ÄúPhysical AI‚Äù Edge Kit**

| Component | Model                      | Cost | Role           |
| --------- | -------------------------- | ---- | -------------- |
| Brain     | Jetson Orin Nano / NX      | ‚Äî    | Deploy ROS/AI  |
| Eyes      | Intel RealSense D435i/D455 | ‚Äî    | RGB + Depth    |
| IMU       | USB IMU (BNO055)           | ‚Äî    | Balance        |
| Mic       | USB Microphone             | ‚Äî    | Voice commands |

---

## **3. Robot Lab Options**

### **Option A: Proxy Robots (Budget)**

* **Unitree Go2 Edu**
  Pros: Cheap, ROS 2 support
  Cons: Not humanoid

### **Option B: Mini Humanoids**

* Unitree G1 (~$16k)
* Robotis OP3 (~$12k)
* Hiwonder TonyPi (~$600, limited AI capability)

### **Option C: Premium Lab**

* **Unitree G1 Humanoid**

---

## **4. Architecture Summary**

| Component  | Hardware          | Function              |
| ---------- | ----------------- | --------------------- |
| Sim Rig    | RTX 4080 PC       | Training + simulation |
| Edge Brain | Jetson Orin Nano  | On-device inference   |
| Sensors    | RealSense + Lidar | Real-world perception |
| Robot      | Unitree Go2/G1    | Motor actions         |

---

# **Option 2: Cloud-Based Lab (High OpEx)**

### **1. Cloud Workstations**

* **AWS g5.2xlarge** or **g6e.xlarge**
* Cost: ~$205 per quarter

### **2. Local Bridge Hardware**

* Still requires Jetson kit
* Still requires at least one robot

---

# **Economy Jetson Student Kit (~$700)**

| Component | Model                          | Price | Notes        |
| --------- | ------------------------------ | ----- | ------------ |
| Brain     | Jetson Orin Nano Super Dev Kit | $249  | 40 TOPS      |
| Eyes      | Intel RealSense D435i          | $349  | Includes IMU |
| Ears      | ReSpeaker USB Mic              | $69   | Voice        |
| Misc      | SD card + wires                | $30   | Required     |

---

# **The Latency Trap**

Cloud simulation ‚Üí Real robot control has latency risks.
Solution:

* Train in cloud
* Export weights
* Deploy to local Jetson kit

---

